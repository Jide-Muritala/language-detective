{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language classification model using the XLM-RoBERTa transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Filter Dataset:\n",
    "\n",
    "Load the dataset and filter it to include only specific languages (English, Spanish, French, German, and Italian). Then take a sample of the filtered dataset for quick prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id lang                                               text\n",
      "3713910    3955456  eng  The thick clouds which cover Venus cause a \"gr...\n",
      "5368446    5723029  ita                                          Le vedrò.\n",
      "11393369  11860590  eng             Leonid’s eyes turned into a reptile’s.\n",
      "10243780  10703006  eng  At that moment I was walking towards the station.\n",
      "11251489  11717624  eng  Pietro came as fast as he could to the costume...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"sentences.csv\", sep=\"\\t\", header=None, names=[\"id\", \"lang\", \"text\"])\n",
    "\n",
    "# Filter dataset for a few languages (e.g., English, Spanish, French, German, Italian)\n",
    "languages = [\"eng\", \"spa\", \"fra\", \"deu\", \"ita\"]\n",
    "df_filtered = df[df['lang'].isin(languages)]\n",
    "\n",
    "# Select a sample for quick prototyping\n",
    "df_sample = df_filtered.sample(1000)\n",
    "print(df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for Training: \n",
    "\n",
    "Extract texts and labels, then split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_sample['text'].tolist()\n",
    "labels = df_sample['lang'].tolist()\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model:\n",
    "\n",
    "Load the XLM-RoBERTa model for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions:\n",
    "\n",
    "Predict the language on the test set and evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier(test_texts)\n",
    "\n",
    "# Extract predicted labels\n",
    "predicted_labels = [prediction['label'] for prediction in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     LABEL_0       0.00      0.00      0.00       0.0\n",
      "         deu       0.00      0.00      0.00      37.0\n",
      "         eng       0.00      0.00      0.00      89.0\n",
      "         fra       0.00      0.00      0.00      19.0\n",
      "         ita       0.00      0.00      0.00      41.0\n",
      "         spa       0.00      0.00      0.00      14.0\n",
      "\n",
      "    accuracy                           0.00     200.0\n",
      "   macro avg       0.00      0.00      0.00     200.0\n",
      "weighted avg       0.00      0.00      0.00     200.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(test_labels, predicted_labels))\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This is a test sentence in English.\n",
      "Predicted Language: English\n",
      "\n",
      "Sentence: Esta es una frase de prueba en español.\n",
      "Predicted Language: English\n",
      "\n",
      "Sentence: C'est une phrase de test en français.\n",
      "Predicted Language: English\n",
      "\n",
      "Sentence: Dies ist ein Testsatz auf Deutsch.\n",
      "Predicted Language: English\n",
      "\n",
      "Sentence: Questa è una frase di prova in italiano.\n",
      "Predicted Language: English\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "classifier = pipeline(\"text-classification\", model=\"xlm-roberta-base\")\n",
    "\n",
    "# Define the mapping from label to actual language\n",
    "label_to_language = {\n",
    "    'LABEL_0': 'English',\n",
    "    'LABEL_1': 'Spanish',\n",
    "    'LABEL_2': 'French',\n",
    "    'LABEL_3': 'German',\n",
    "    'LABEL_4': 'Italian'\n",
    "}\n",
    "\n",
    "# Example sentences to test the classifier\n",
    "sentences = [\n",
    "    \"This is a test sentence in English.\",\n",
    "    \"Esta es una frase de prueba en español.\",\n",
    "    \"C'est une phrase de test en français.\",\n",
    "    \"Dies ist ein Testsatz auf Deutsch.\",\n",
    "    \"Questa è una frase di prova in italiano.\"\n",
    "]\n",
    "\n",
    "# Predict the language and map the label to actual language name\n",
    "for sentence in sentences:\n",
    "    prediction = classifier(sentence)\n",
    "    label = prediction[0]['label']\n",
    "    language = label_to_language[label]\n",
    "    \n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Predicted Language: {language}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Tokenize Additional Dataset:\n",
    "\n",
    "load a dataset (PAWS-X) for training and testing the model, and apply tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load PAWS-X for English, Spanish, German, French, and Italian\n",
    "dataset_en = load_dataset('xtreme', 'PAWS-X.en')\n",
    "dataset_es = load_dataset('xtreme', 'PAWS-X.es')\n",
    "dataset_de = load_dataset('xtreme', 'PAWS-X.de')\n",
    "dataset_fr = load_dataset('xtreme', 'PAWS-X.fr')\n",
    "dataset_it = load_dataset('xtreme', 'PAN-X.it')\n",
    "\n",
    "# Concatenate the datasets\n",
    "train_dataset = concatenate_datasets([dataset_en['train'], dataset_es['train'], dataset_de['train'], dataset_fr['train'], dataset_it['train']])\n",
    "test_dataset = concatenate_datasets([dataset_en['test'], dataset_es['test'], dataset_de['test'], dataset_fr['test'], dataset_it['test']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "# Tokenize the dataset; adjust 'sentence1' and 'sentence2' if needed based on dataset structure\n",
    "def tokenize(batch):\n",
    "    # Concatenate sentence1 and sentence2, replacing None values with an empty string\n",
    "    combined_sentences = [(s1 if s1 is not None else \"\") + \" \" + (s2 if s2 is not None else \"\") for s1, s2 in zip(batch['sentence1'], batch['sentence2'])]\n",
    "    return tokenizer(combined_sentences, padding=\"max_length\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply tokenization to train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset.map(tokenize, batched=True)\n",
    "test_data = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Labels to Integer Format\n",
    "\n",
    "Filter out samples with None labels and convert labels to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 217355/217355 [00:23<00:00, 9383.42 examples/s] \n",
      "Filter: 100%|██████████| 18000/18000 [00:02<00:00, 8783.31 examples/s]\n",
      "Map: 100%|██████████| 197355/197355 [00:25<00:00, 7652.31 examples/s]\n",
      "Map: 100%|██████████| 8000/8000 [00:01<00:00, 7494.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter Out None Labels by removing samples with None as the label\n",
    "train_data = train_data.filter(lambda x: x['label'] is not None)\n",
    "test_data = test_data.filter(lambda x: x['label'] is not None)\n",
    "\n",
    "# Convert remaining labels to integers\n",
    "def convert_labels(batch):\n",
    "    batch['label'] = int(batch['label'])\n",
    "    return batch\n",
    "\n",
    "train_data = train_data.map(convert_labels)\n",
    "test_data = test_data.map(convert_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set format for PyTorch:\n",
    "\n",
    "Prepare the dataset for use with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train_data and test_data are ready to be used with Trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, \n",
    "Set up the model and specify training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=5)  # 5 for the five languages you're using\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Trainer:\n",
    "\n",
    "Initialize the Trainer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate Model: \n",
    "\n",
    "Finally, Train the model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with New Sentences:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
